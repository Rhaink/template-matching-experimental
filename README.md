# Matching Experimental - Advanced Template Matching Research Platform

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-experimental-yellow.svg)

**A comprehensive experimental platform for template matching landmark detection with eigenpatches, geometric constraints, and AI-assisted research capabilities.**

---

## ğŸ¯ Overview

The **Matching Experimental** platform is designed to replicate, analyze, and improve upon the baseline Template Matching with Eigenpatches algorithm that achieves **5.63Â±0.17 pixels** mean error on 159 test images. This platform serves as a research sandbox for systematic experimentation, parameter optimization, and novel algorithm development.

### Key Features

- ğŸ”¬ **Complete Pipeline Replication** - Exact reproduction of 5.86px baseline results
- âš™ï¸ **Configuration-Driven Architecture** - YAML-based parameter externalization  
- ğŸ§ª **Systematic Experimentation** - TDD approach with comprehensive test coverage
- ğŸ“Š **Enhanced Evaluation** - HTML reports, interactive visualizations, statistical analysis
- ğŸ¤– **AI-Assisted Research** - Prompt-engineered notebooks for hypothesis generation
- ğŸ“ˆ **Baseline Comparison** - Automatic comparison with documented performance
- ğŸ› ï¸ **Modular Design** - Adapters to original code maintaining compatibility

## ğŸ—ï¸ Architecture

```
matching_experimental/
â”œâ”€â”€ ğŸ“ core/                    # Experimental adaptations of original algorithms
â”‚   â”œâ”€â”€ experimental_eigenpatches.py    # PCA eigenpatches with config & logging
â”‚   â”œâ”€â”€ experimental_predictor.py       # Landmark predictor with analysis tools
â”‚   â””â”€â”€ experimental_evaluator.py       # Enhanced evaluation with HTML reports
â”œâ”€â”€ ğŸ“ configs/                 # YAML configuration management
â”‚   â”œâ”€â”€ default_config.yaml             # Baseline replication parameters
â”‚   â””â”€â”€ experimental_configs.yaml       # Systematic parameter variations
â”œâ”€â”€ ğŸ“ scripts/                 # Production-ready CLI tools
â”‚   â”œâ”€â”€ train_experimental.py           # Enhanced training with validation
â”‚   â”œâ”€â”€ process_experimental.py         # Batch processing with progress tracking
â”‚   â”œâ”€â”€ evaluate_experimental.py        # Comprehensive evaluation pipeline
â”‚   â””â”€â”€ run_full_pipeline.py           # Automated end-to-end workflow
â”œâ”€â”€ ğŸ“ tests/                   # Comprehensive test suite (TDD approach)
â”‚   â”œâ”€â”€ test_eigenpatches.py           # Unit tests for eigenpatches
â”‚   â”œâ”€â”€ test_predictor.py              # Unit tests for landmark predictor
â”‚   â”œâ”€â”€ test_evaluator.py              # Unit tests for evaluation
â”‚   â”œâ”€â”€ test_integration.py            # Integration and pipeline tests
â”‚   â””â”€â”€ fixtures/                       # Synthetic test data generators
â”œâ”€â”€ ğŸ“ notebooks/               # Interactive analysis and experimentation
â”‚   â”œâ”€â”€ 00_QuickStart.ipynb            # 2-minute introduction and demo
â”‚   â”œâ”€â”€ 01_Mathematical_Analysis.ipynb  # Deep mathematical foundations
â”‚   â”œâ”€â”€ 02_Results_Analysis.ipynb       # Real experimental results analysis
â”‚   â”œâ”€â”€ 03_Prompt_Driven_Experiments.ipynb # AI-assisted research framework
â”‚   â””â”€â”€ 04_Parameter_Sensitivity.ipynb  # Systematic parameter optimization
â””â”€â”€ ğŸ“ docs/                    # Academic-level documentation
    â”œâ”€â”€ Mathematical_Foundations.md     # LaTeX equations and theory
    â””â”€â”€ Experimental_Roadmap.md        # Future research directions
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
cd /path/to/Tesiscopia
git pull  # Ensure you have the latest code

# Install dependencies
cd matching_experimental
pip install -r requirements.txt

# Install in development mode
pip install -e .
```

### 2. Verify Installation

```bash
# Run tests to verify everything works
make test

# Or manually:
python -m pytest tests/ -v
```

### 3. Replicate Baseline Results

```bash
# Train model with baseline configuration
python scripts/train_experimental.py \
    --config configs/default_config.yaml

# Process 159 test images
python scripts/process_experimental.py \
    --config configs/default_config.yaml \
    --model models/experimental_predictor_*.pkl

# Generate comprehensive evaluation
python scripts/evaluate_experimental.py \
    results/processing_results_*.pkl \
    --config configs/default_config.yaml
```

### 4. Run Complete Pipeline

```bash
# Automated end-to-end execution
python scripts/run_full_pipeline.py \
    --config configs/default_config.yaml \
    --output-dir results/baseline_replication
```

**Expected Results:** Mean error of ~5.63Â±0.17 pixels on test dataset, matching documented baseline performance.

## ğŸ“Š Baseline Performance

The system replicates and validates the following documented performance:

| Metric | Value | Source |
|--------|--------|---------|
| **Mean Error** | 5.63Â±0.17 pixels | coordenadas_prueba_1.csv (159 images) |
| **Best Landmark** | L11 (Right_Lower_Edge): 5.297Â±3.016 px | Per-landmark evaluation |
| **Worst Landmark** | L9 (Center_Medial): 5.995Â±3.158 px | Per-landmark evaluation |
| **By Pathology** | Normal: 5.501Â±0.262 px<br>Viral: 5.708Â±0.389 px<br>COVID: 5.764Â±0.388 px | Category breakdown |
| **Processing Speed** | ~0.2 seconds/image | Typical performance |

## ğŸ”¬ Mathematical Foundations

### Algorithm Overview

The template matching algorithm combines several mathematical components:

1. **Eigenpatches (PCA-based Template Matching)**
   ```
   E_recon(x,y) = ||P(x,y) - Î¼||Â² - ||P_proj(x,y) - Î¼||Â²
   ```
   - **P(x,y)**: Image patch at position (x,y)
   - **Î¼**: Mean patch from training data
   - **P_proj**: PCA reconstruction using k components

2. **Statistical Shape Models with Constraints**
   ```
   x = xÌ„ + Î¦b,  subject to |b_i| â‰¤ 3âˆšÎ»_i
   ```
   - **xÌ„**: Mean shape from Procrustes-aligned training shapes
   - **Î¦**: Shape eigenvectors (modes of variation)
   - **b**: Shape parameters with 3Ïƒ constraints

3. **Multi-scale Optimization**
   - Coarse-to-fine search using Gaussian pyramids
   - Iterative refinement with geometric constraint projection
   - Convergence based on landmark displacement threshold

4. **Critical Coordinate Scaling**
   ```
   landmarks_scaled = landmarks_64x64 Ã— 4.67
   ```
   - **Essential**: Scale factor from 64Ã—64 reference to 299Ã—299 images
   - **Failure Mode**: Incorrect scaling breaks the entire pipeline

For complete mathematical derivations, see [Mathematical_Foundations.md](docs/Mathematical_Foundations.md).

## ğŸ§ª Experimental Capabilities

### Configuration-Based Experiments

All parameters are externalized in YAML for systematic experimentation:

```yaml
# Example experimental configuration
eigenpatches:
  patch_size: [15, 21, 31]        # Multi-size experiment
  n_components: [15, 20, 25, 30]  # Component sensitivity
  pyramid_levels: [2, 3, 4]       # Multi-scale analysis

landmark_predictor:
  lambda_shape: [0.05, 0.1, 0.2]  # Constraint strength
  max_iterations: [3, 5, 10]      # Convergence analysis
```

### Automated Evaluation

Enhanced evaluation system provides:

- **HTML Interactive Reports** with plotly visualizations
- **Statistical Significance Testing** (Wilcoxon, bootstrap CI)
- **Automatic Baseline Comparison** with performance categorization
- **Per-landmark Analysis** with anatomical insights
- **Multi-format Export** (JSON, YAML, CSV, LaTeX)

### AI-Assisted Research

The platform includes prompt-engineered notebooks for:

- **Hypothesis Generation** with structured templates
- **Experiment Design** with systematic methodology
- **Results Interpretation** with AI consultation framework
- **Research Documentation** with automatic session tracking

## ğŸ“ˆ Experimental Results

### Parameter Sensitivity Analysis

| Parameter | Baseline | Optimal Range | Impact |
|-----------|----------|---------------|---------|
| patch_size | 21 | 19-25 | Â±0.3 px |
| n_components | 20 | 18-25 | Â±0.2 px |
| pyramid_levels | 3 | 3-4 | Â±0.1 px |
| lambda_shape | 0.1 | 0.08-0.12 | Â±0.4 px |

### Novel Approaches Tested

1. **Adaptive Template Matching** - Eliminates border padding issues (47.6% â†’ 0% loss)
2. **Matching Geometric Hybrid** - Combines TM precision with geometric construction (16.3% improvement on quartiles)
3. **Delaunay Morphing Integration** - Uses exact TM landmarks for anatomical warping

## ğŸ› ï¸ Development Workflow

### Test-Driven Development

```bash
# Run full test suite
make test

# Run specific test categories
python -m pytest tests/test_eigenpatches.py -v     # Unit tests
python -m pytest tests/test_integration.py -v     # Integration tests
python -m pytest tests/ -k "predictor" -v         # Pattern-based testing
```

### Performance Validation

```bash
# Quick performance check
python scripts/evaluate_experimental.py \
    --compare-only \
    --ground-truth coordenadas/coordenadas_prueba_1.csv

# Full pipeline validation
make pipeline
```

### Configuration Management

```bash
# Validate configuration
python -c "
import yaml
with open('configs/default_config.yaml') as f:
    config = yaml.safe_load(f)
print('âœ… Configuration valid')
"

# Test configuration changes
python scripts/train_experimental.py \
    --config configs/experimental_configs.yaml \
    --validate-only
```

## ğŸ“š Documentation Structure

### Quick References
- **[QuickStart Notebook](notebooks/00_QuickStart.ipynb)** - 2-minute demo and tutorial
- **[CLI Reference](docs/CLI_Reference.md)** - Command-line usage examples
- **[Configuration Guide](docs/Configuration_Guide.md)** - Parameter tuning guidelines

### Deep Dives
- **[Mathematical Analysis](notebooks/01_Mathematical_Analysis.ipynb)** - Complete theoretical foundations
- **[Results Analysis](notebooks/02_Results_Analysis.ipynb)** - Real experimental data exploration
- **[Parameter Sensitivity](notebooks/04_Parameter_Sensitivity.ipynb)** - Systematic optimization

### Research Framework
- **[Prompt-Driven Experiments](notebooks/03_Prompt_Driven_Experiments.ipynb)** - AI-assisted research methodology
- **[Experimental Roadmap](docs/Experimental_Roadmap.md)** - Future research directions

## ğŸ”§ Advanced Usage

### Custom Experiment Design

```python
# Example: Custom parameter sweep
from core.experimental_predictor import ExperimentalLandmarkPredictor
from core.experimental_evaluator import ExperimentalEvaluator

# Define parameter grid
parameter_grid = {
    'patch_size': [15, 21, 31],
    'n_components': [15, 20, 25],
    'lambda_shape': [0.05, 0.1, 0.2]
}

# Automated experimentation
for params in parameter_combinations(parameter_grid):
    config = update_config(base_config, params)
    predictor = ExperimentalLandmarkPredictor(config=config)
    # ... train and evaluate
```

### Integration with Original System

```python
# The experimental system is designed as a drop-in replacement
from core.experimental_predictor import ExperimentalLandmarkPredictor

# Compatible with original template_matching workflows
predictor = ExperimentalLandmarkPredictor(config="configs/default_config.yaml")
predictor.train(images, landmarks)  # Same API as original
landmarks = predictor.predict_landmarks(image)  # Enhanced functionality
```

### Batch Processing

```bash
# Process multiple datasets
for dataset in coordenadas_entrenamiento_*.csv; do
    python scripts/train_experimental.py \
        --coordinates "$dataset" \
        --output "models/model_$(basename $dataset .csv).pkl"
done
```

## ğŸš¦ Performance Benchmarks

| Operation | Time | Memory | Notes |
|-----------|------|---------|-------|
| Training (640 images) | ~60s | ~500MB | Including PCA computation |
| Processing (159 images) | ~30s | ~200MB | Batch prediction |
| Evaluation (full analysis) | ~10s | ~100MB | Including visualizations |
| Single prediction | ~0.2s | ~50MB | Per-image processing |

**System Requirements:**
- Python 3.8+
- 4GB RAM (8GB recommended)
- CPU with SSE2 support
- Optional: GPU for accelerated experiments

## ğŸ¤ Contributing

### Research Contributions

1. **Algorithm Improvements** - Submit new approaches via notebooks
2. **Parameter Studies** - Add systematic parameter analysis
3. **Evaluation Metrics** - Enhance evaluation methodology
4. **Documentation** - Improve mathematical explanations

### Code Contributions

1. **Fork and Clone** the repository
2. **Create Feature Branch** following naming conventions
3. **Add Tests** following TDD methodology
4. **Update Documentation** including mathematical explanations
5. **Submit Pull Request** with comprehensive description

### Experimental Protocol

1. **Document Hypothesis** using structured templates
2. **Configure Systematically** using YAML parameter files
3. **Validate Results** against baseline performance
4. **Share Insights** through notebook documentation

## ğŸ“„ License and Citation

### License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### Citation
If you use this platform in your research, please cite:

```bibtex
@misc{matching_experimental_2024,
    title={Matching Experimental: Advanced Template Matching Research Platform},
    author={Template Matching Research Team},
    year={2024},
    howpublished={\\url{https://github.com/your-repo/matching_experimental}},
    note={Experimental platform for lung landmark detection research}
}
```

### Related Work
- **Baseline Algorithm**: Template Matching with Eigenpatches (5.63Â±0.17 px)
- **Original Implementation**: `template_matching/` directory
- **Enhanced Variants**: `matching_geometric/`, `delaunay_morphing/`, `template_matching_adaptive/`

## ğŸ†˜ Support and Troubleshooting

### Common Issues

**Issue**: Model training fails with "No images loaded"
```bash
# Solution: Check coordinate file format (no header)
python -c "
import pandas as pd
df = pd.read_csv('coordenadas/coordenadas_entrenamiento_1.csv', header=None)
print(f'Loaded {len(df)} rows with {df.shape[1]} columns')
"
```

**Issue**: Predictions have wrong scale
```bash
# Solution: Verify coordinate scaling factor
python -c "
config = yaml.safe_load(open('configs/default_config.yaml'))
scale = config['image_processing']['coordinate_scale_factor']
print(f'Scale factor: {scale} (should be ~4.67 for 299x299 images)')
"
```

**Issue**: Poor convergence in iterative refinement
```bash
# Solution: Check geometric constraint parameters
python scripts/evaluate_experimental.py \
    --analyze-convergence \
    --max-iterations 10
```

### Getting Help

- **ğŸ“– Documentation**: Check [docs/](docs/) directory for detailed guides
- **ğŸ§ª Examples**: Run [notebooks/](notebooks/) for interactive tutorials  
- **ğŸ› Issues**: Submit detailed bug reports with configuration and data
- **ğŸ’¬ Discussions**: Use GitHub Discussions for research questions

### Performance Optimization

```bash
# Enable performance monitoring
export PYTHONPATH="${PWD}:$PYTHONPATH"
python -m cProfile -o profile.stats scripts/process_experimental.py
python -c "
import pstats
stats = pstats.Stats('profile.stats')
stats.sort_stats('cumulative').print_stats(20)
"
```

---

## ğŸ¯ Next Steps

1. **ğŸ“Š Replicate Baseline** - Run the full pipeline to verify 5.63Â±0.17 px performance
2. **ğŸ§ª Explore Parameters** - Use `configs/experimental_configs.yaml` for systematic studies
3. **ğŸ¤– AI-Assisted Research** - Try `notebooks/03_Prompt_Driven_Experiments.ipynb` for guided experimentation
4. **ğŸ“ˆ Novel Approaches** - Implement and test your algorithmic improvements
5. **ğŸ“ Document Findings** - Share insights through notebook documentation

**Happy experimenting! ğŸš€**

---

*Last updated: 2024-01-XX | Version: 1.0.0 | Status: Experimental*