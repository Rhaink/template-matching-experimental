{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt-Driven Experiments with AI Assistance\n",
    "\n",
    "This notebook provides a framework for conducting AI-assisted research experiments in template matching. It includes:\n",
    "\n",
    "1. **Structured experiment templates** for LLM interaction\n",
    "2. **Hypothesis generation and testing** workflows\n",
    "3. **Automated experiment execution** with result analysis\n",
    "4. **Research documentation** and knowledge accumulation\n",
    "5. **Iterative improvement** cycles with AI feedback\n",
    "\n",
    "**Use this notebook to:**\n",
    "- Generate research hypotheses with AI assistance\n",
    "- Design and execute systematic experiments\n",
    "- Analyze results and derive insights\n",
    "- Build on previous experimental knowledge\n",
    "\n",
    "## How to Use This Notebook\n",
    "\n",
    "1. **Define your research question** in the Research Context section\n",
    "2. **Use the AI Consultation** cells to get algorithmic insights\n",
    "3. **Generate hypotheses** using the structured templates\n",
    "4. **Execute experiments** with the provided framework\n",
    "5. **Analyze and document** your findings\n",
    "6. **Iterate** based on results and AI feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project paths\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from core.experimental_predictor import ExperimentalLandmarkPredictor\n",
    "from core.experimental_evaluator import ExperimentalEvaluator\n",
    "from tests.fixtures import create_synthetic_images, create_synthetic_landmarks\n",
    "\n",
    "print(\"üöÄ Prompt-Driven Experiments Environment Initialized!\")\n",
    "print(f\"üìÅ Project root: {PROJECT_ROOT}\")\n",
    "print(f\"üìÖ Session started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Context Setup\n",
    "\n",
    "**üìã Define your research question and context here:**\n",
    "\n",
    "Edit the cell below to specify:\n",
    "- Your research objective\n",
    "- Current baseline performance\n",
    "- Specific areas you want to investigate\n",
    "- Any constraints or requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ RESEARCH CONTEXT - Edit this section for your specific investigation\n",
    "\n",
    "RESEARCH_CONTEXT = {\n",
    "    \"objective\": \"Improve template matching accuracy beyond 5.63¬±0.17 pixel baseline\",\n",
    "    \"baseline_performance\": {\n",
    "        \"mean_error\": 5.63,\n",
    "        \"std_error\": 0.17,\n",
    "        \"dataset\": \"coordenadas_prueba_1.csv (159 images)\",\n",
    "        \"method\": \"Template Matching with Eigenpatches\"\n",
    "    },\n",
    "    \"investigation_areas\": [\n",
    "        \"Patch size optimization\",\n",
    "        \"PCA component selection\",\n",
    "        \"Multi-scale pyramid configuration\",\n",
    "        \"Geometric constraint tuning\",\n",
    "        \"Hybrid approaches\"\n",
    "    ],\n",
    "    \"constraints\": {\n",
    "        \"computational_budget\": \"Reasonable training/inference time\",\n",
    "        \"data_requirements\": \"Work with existing coordinate files\",\n",
    "        \"interpretability\": \"Maintain algorithmic transparency\"\n",
    "    },\n",
    "    \"success_criteria\": {\n",
    "        \"primary\": \"Mean error < 5.0 pixels\",\n",
    "        \"secondary\": \"Improved consistency (lower std)\",\n",
    "        \"tertiary\": \"Better per-landmark performance\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üéØ Research Context Defined:\")\n",
    "print(f\"   Objective: {RESEARCH_CONTEXT['objective']}\")\n",
    "print(f\"   Baseline: {RESEARCH_CONTEXT['baseline_performance']['mean_error']}¬±{RESEARCH_CONTEXT['baseline_performance']['std_error']} pixels\")\n",
    "print(f\"   Success: {RESEARCH_CONTEXT['success_criteria']['primary']}\")\n",
    "print(f\"   Areas: {len(RESEARCH_CONTEXT['investigation_areas'])} investigation areas defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Consultation Framework\n",
    "\n",
    "Use these cells to interact with AI assistants for research guidance. Each cell provides a structured prompt template for different types of AI consultation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ AI Consultation Cell #1: Algorithm Analysis\n",
    "\n",
    "**Use this cell to get AI insights on algorithmic improvements:**\n",
    "\n",
    "---\n",
    "\n",
    "**System:** You are an expert in computer vision and machine learning, specializing in landmark detection and template matching algorithms. Provide detailed, actionable insights based on the latest research.\n",
    "\n",
    "**User:** I'm working on template matching for lung landmark detection using eigenpatches (PCA-based templates) with geometric constraints. Current performance is 5.63¬±0.17 pixels mean error on 159 test images.\n",
    "\n",
    "**Algorithm details:**\n",
    "- Patch size: 21√ó21 pixels\n",
    "- PCA components: 20\n",
    "- Pyramid levels: 3 (multi-scale)\n",
    "- Geometric constraints: |b_i| ‚â§ 3‚àöŒª_i\n",
    "- Max iterations: 5\n",
    "\n",
    "**Question:** What are the top 3 most promising directions to improve accuracy beyond this baseline? Consider both theoretical foundations and practical implementation aspects.\n",
    "\n",
    "**Assistant:** [PASTE AI RESPONSE HERE]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ AI Consultation Cell #2: Parameter Optimization\n",
    "\n",
    "**Use this cell for parameter tuning guidance:**\n",
    "\n",
    "---\n",
    "\n",
    "**System:** You are an expert in hyperparameter optimization and algorithm tuning for computer vision applications.\n",
    "\n",
    "**User:** Based on the template matching setup described above, I want to systematically optimize the key parameters. Current configuration:\n",
    "\n",
    "```yaml\n",
    "eigenpatches:\n",
    "  patch_size: 21\n",
    "  n_components: 20\n",
    "  pyramid_levels: 3\n",
    "landmark_predictor:\n",
    "  lambda_shape: 0.1\n",
    "  max_iterations: 5\n",
    "  convergence_threshold: 0.5\n",
    "```\n",
    "\n",
    "**Question:** \n",
    "1. Which parameters have the highest impact on accuracy?\n",
    "2. What ranges should I explore for each parameter?\n",
    "3. What's an efficient optimization strategy (grid search, random, Bayesian)?\n",
    "4. How should I handle parameter interactions?\n",
    "\n",
    "**Assistant:** [PASTE AI RESPONSE HERE]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ AI Consultation Cell #3: Novel Approaches\n",
    "\n",
    "**Use this cell for exploring innovative methods:**\n",
    "\n",
    "---\n",
    "\n",
    "**System:** You are a research scientist specializing in cutting-edge computer vision techniques and novel algorithmic approaches.\n",
    "\n",
    "**User:** I want to explore hybrid or novel approaches to improve template matching beyond traditional eigenpatches. Current baseline uses PCA-based eigenpatches with statistical shape models.\n",
    "\n",
    "**Constraints:**\n",
    "- Must work with existing training data (coordinate files)\n",
    "- Should maintain interpretability\n",
    "- Reasonable computational requirements\n",
    "\n",
    "**Question:** Suggest 3 innovative approaches that could be combined with or replace eigenpatches:\n",
    "1. Modern techniques (deep learning, etc.)\n",
    "2. Advanced classical methods\n",
    "3. Hybrid combinations\n",
    "\n",
    "For each approach, explain the theoretical advantage and implementation feasibility.\n",
    "\n",
    "**Assistant:** [PASTE AI RESPONSE HERE]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Generation Framework\n",
    "\n",
    "Based on AI consultation and research context, generate structured hypotheses for systematic testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ HYPOTHESIS GENERATION FRAMEWORK\n",
    "\n",
    "@dataclass\n",
    "class ResearchHypothesis:\n",
    "    \"\"\"Structured hypothesis for systematic testing.\"\"\"\n",
    "    id: str\n",
    "    title: str\n",
    "    description: str\n",
    "    rationale: str\n",
    "    ai_insight: str\n",
    "    configuration_changes: Dict[str, Any]\n",
    "    expected_improvement: str\n",
    "    test_method: str\n",
    "    success_criteria: str\n",
    "    risk_level: str  # \"low\", \"medium\", \"high\"\n",
    "    estimated_time: str\n",
    "    \n",
    "# Generate hypotheses based on AI consultation\n",
    "# Edit these based on the AI responses above\n",
    "\n",
    "HYPOTHESES = [\n",
    "    ResearchHypothesis(\n",
    "        id=\"H1\",\n",
    "        title=\"Adaptive Patch Size Selection\",\n",
    "        description=\"Use different patch sizes for different landmarks based on local feature complexity\",\n",
    "        rationale=\"Different anatomical regions may benefit from different receptive field sizes\",\n",
    "        ai_insight=\"[Insert relevant AI insight from consultation above]\",\n",
    "        configuration_changes={\n",
    "            \"eigenpatches\": {\n",
    "                \"patch_size\": [15, 21, 31],  # Per-landmark selection\n",
    "                \"adaptive_patches\": True\n",
    "            }\n",
    "        },\n",
    "        expected_improvement=\"5-10% reduction in mean error\",\n",
    "        test_method=\"Train models with different patch sizes per landmark\",\n",
    "        success_criteria=\"Mean error < 5.3 pixels\",\n",
    "        risk_level=\"medium\",\n",
    "        estimated_time=\"2-3 hours\"\n",
    "    ),\n",
    "    \n",
    "    ResearchHypothesis(\n",
    "        id=\"H2\",\n",
    "        title=\"Increased PCA Components\",\n",
    "        description=\"Use more PCA components to capture finer eigenpatches variations\",\n",
    "        rationale=\"Current 20 components may not capture sufficient appearance variation\",\n",
    "        ai_insight=\"[Insert relevant AI insight from consultation above]\",\n",
    "        configuration_changes={\n",
    "            \"eigenpatches\": {\n",
    "                \"n_components\": 35\n",
    "            }\n",
    "        },\n",
    "        expected_improvement=\"Improved precision for challenging landmarks\",\n",
    "        test_method=\"Compare 20 vs 35 components on same test set\",\n",
    "        success_criteria=\"Reduced worst-landmark error by 0.3 pixels\",\n",
    "        risk_level=\"low\",\n",
    "        estimated_time=\"1 hour\"\n",
    "    ),\n",
    "    \n",
    "    ResearchHypothesis(\n",
    "        id=\"H3\",\n",
    "        title=\"Relaxed Geometric Constraints\",\n",
    "        description=\"Reduce lambda_shape to allow more shape flexibility\",\n",
    "        rationale=\"Current constraints may be too restrictive for pathological cases\",\n",
    "        ai_insight=\"[Insert relevant AI insight from consultation above]\",\n",
    "        configuration_changes={\n",
    "            \"landmark_predictor\": {\n",
    "                \"lambda_shape\": 0.05\n",
    "            }\n",
    "        },\n",
    "        expected_improvement=\"Better handling of anatomical variations\",\n",
    "        test_method=\"Test on images with highest current error\",\n",
    "        success_criteria=\"Improved worst-case performance\",\n",
    "        risk_level=\"medium\",\n",
    "        estimated_time=\"45 minutes\"\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"üìã Generated {len(HYPOTHESES)} research hypotheses:\")\n",
    "for h in HYPOTHESES:\n",
    "    print(f\"   {h.id}: {h.title} (Risk: {h.risk_level}, Time: {h.estimated_time})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Execution Framework\n",
    "\n",
    "Automated framework for executing and tracking experiments based on generated hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¨ EXPERIMENT EXECUTION FRAMEWORK\n",
    "\n",
    "@dataclass\n",
    "class ExperimentResult:\n",
    "    \"\"\"Container for experiment results.\"\"\"\n",
    "    hypothesis_id: str\n",
    "    timestamp: str\n",
    "    configuration: Dict[str, Any]\n",
    "    metrics: Dict[str, float]\n",
    "    success: bool\n",
    "    notes: str\n",
    "    processing_time: float\n",
    "\n",
    "class ExperimentRunner:\n",
    "    \"\"\"Automated experiment execution and tracking.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_config_path: str):\n",
    "        with open(base_config_path, 'r') as f:\n",
    "            self.base_config = yaml.safe_load(f)\n",
    "        self.results = []\n",
    "        \n",
    "    def run_hypothesis_experiment(self, hypothesis: ResearchHypothesis, \n",
    "                                test_images: List[np.ndarray],\n",
    "                                test_landmarks: List[np.ndarray]) -> ExperimentResult:\n",
    "        \"\"\"Execute experiment for a specific hypothesis.\"\"\"\n",
    "        print(f\"üß™ Executing experiment: {hypothesis.id} - {hypothesis.title}\")\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Create modified configuration\n",
    "        experiment_config = self.base_config.copy()\n",
    "        \n",
    "        # Apply hypothesis configuration changes\n",
    "        for section, changes in hypothesis.configuration_changes.items():\n",
    "            if section in experiment_config:\n",
    "                experiment_config[section].update(changes)\n",
    "            else:\n",
    "                experiment_config[section] = changes\n",
    "        \n",
    "        # Disable logging for cleaner output\n",
    "        experiment_config['logging'] = {\n",
    "            'level': 'WARNING',\n",
    "            'console_logging': False,\n",
    "            'file_logging': False\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Quick synthetic training for demonstration\n",
    "            train_images = create_synthetic_images(n_images=20, seed=42)\n",
    "            train_landmarks = create_synthetic_landmarks(n_images=20, seed=42)\n",
    "            \n",
    "            # Initialize and train predictor\n",
    "            predictor = ExperimentalLandmarkPredictor(config=experiment_config)\n",
    "            predictor.train(train_images, train_landmarks)\n",
    "            \n",
    "            # Make predictions on test data\n",
    "            predictions = []\n",
    "            for test_image in test_images:\n",
    "                result = predictor.predict_landmarks(test_image)\n",
    "                predictions.append(result.landmarks)\n",
    "            \n",
    "            # Evaluate results\n",
    "            evaluator = ExperimentalEvaluator(config=experiment_config)\n",
    "            eval_results = evaluator.evaluate_method(\n",
    "                predictions=predictions,\n",
    "                ground_truth=test_landmarks,\n",
    "                method_name=f\"Experiment_{hypothesis.id}\"\n",
    "            )\n",
    "            \n",
    "            # Extract metrics\n",
    "            metrics = {\n",
    "                'mean_error': eval_results['basic_metrics']['mean_error'],\n",
    "                'std_error': eval_results['basic_metrics']['std_error'],\n",
    "                'median_error': eval_results['basic_metrics']['median_error'],\n",
    "                'min_error': eval_results['basic_metrics']['min_error'],\n",
    "                'max_error': eval_results['basic_metrics']['max_error'],\n",
    "                'improvement_vs_baseline': eval_results['baseline_comparison']['improvement']\n",
    "            }\n",
    "            \n",
    "            # Determine success based on hypothesis criteria\n",
    "            success = self._evaluate_success(hypothesis, metrics)\n",
    "            \n",
    "            processing_time = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            result = ExperimentResult(\n",
    "                hypothesis_id=hypothesis.id,\n",
    "                timestamp=start_time.isoformat(),\n",
    "                configuration=experiment_config,\n",
    "                metrics=metrics,\n",
    "                success=success,\n",
    "                notes=f\"Completed successfully in {processing_time:.1f}s\",\n",
    "                processing_time=processing_time\n",
    "            )\n",
    "            \n",
    "            print(f\"   ‚úÖ Success: {success}\")\n",
    "            print(f\"   üìä Mean error: {metrics['mean_error']:.3f} pixels\")\n",
    "            print(f\"   üìà Improvement: {metrics['improvement_vs_baseline']:+.1f}%\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            processing_time = (datetime.now() - start_time).total_seconds()\n",
    "            result = ExperimentResult(\n",
    "                hypothesis_id=hypothesis.id,\n",
    "                timestamp=start_time.isoformat(),\n",
    "                configuration=experiment_config,\n",
    "                metrics={'error': str(e)},\n",
    "                success=False,\n",
    "                notes=f\"Failed with error: {e}\",\n",
    "                processing_time=processing_time\n",
    "            )\n",
    "            print(f\"   ‚ùå Failed: {e}\")\n",
    "        \n",
    "        self.results.append(result)\n",
    "        return result\n",
    "    \n",
    "    def _evaluate_success(self, hypothesis: ResearchHypothesis, metrics: Dict[str, float]) -> bool:\n",
    "        \"\"\"Evaluate if experiment meets success criteria.\"\"\"\n",
    "        # Simple success evaluation based on improvement\n",
    "        if 'improvement_vs_baseline' in metrics:\n",
    "            return metrics['improvement_vs_baseline'] > 0\n",
    "        return False\n",
    "    \n",
    "    def get_summary(self) -> pd.DataFrame:\n",
    "        \"\"\"Get summary of all experiments.\"\"\"\n",
    "        if not self.results:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        summary_data = []\n",
    "        for result in self.results:\n",
    "            row = {\n",
    "                'Hypothesis_ID': result.hypothesis_id,\n",
    "                'Success': result.success,\n",
    "                'Mean_Error': result.metrics.get('mean_error', 'N/A'),\n",
    "                'Improvement_%': result.metrics.get('improvement_vs_baseline', 'N/A'),\n",
    "                'Processing_Time_s': result.processing_time,\n",
    "                'Notes': result.notes\n",
    "            }\n",
    "            summary_data.append(row)\n",
    "        \n",
    "        return pd.DataFrame(summary_data)\n",
    "\n",
    "# Initialize experiment runner\n",
    "config_path = PROJECT_ROOT / \"configs\" / \"default_config.yaml\"\n",
    "experiment_runner = ExperimentRunner(str(config_path))\n",
    "\n",
    "print(\"üî¨ Experiment Runner initialized and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Experiments\n",
    "\n",
    "Run the systematic experiments based on your hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ EXECUTE EXPERIMENTS\n",
    "\n",
    "# Create test dataset for experiments\n",
    "print(\"üóÇÔ∏è Creating test dataset for experiments...\")\n",
    "test_images = create_synthetic_images(n_images=5, image_size=(128, 128), seed=100)\n",
    "test_landmarks = create_synthetic_landmarks(n_images=5, image_size=(128, 128), seed=100)\n",
    "print(f\"   Created {len(test_images)} test images\")\n",
    "\n",
    "# Execute all hypotheses\n",
    "print(f\"\\nüß™ Executing {len(HYPOTHESES)} experiments...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "experiment_results = []\n",
    "for hypothesis in HYPOTHESES:\n",
    "    result = experiment_runner.run_hypothesis_experiment(\n",
    "        hypothesis, test_images, test_landmarks\n",
    "    )\n",
    "    experiment_results.append(result)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\nüèÅ All experiments completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis and Insights\n",
    "\n",
    "Analyze experimental results and generate insights for further research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä RESULTS ANALYSIS\n",
    "\n",
    "# Get experiment summary\n",
    "summary_df = experiment_runner.get_summary()\n",
    "print(\"üìã Experiment Summary:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Detailed analysis\n",
    "print(\"\\nüîç Detailed Analysis:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "successful_experiments = [r for r in experiment_results if r.success]\n",
    "failed_experiments = [r for r in experiment_results if not r.success]\n",
    "\n",
    "print(f\"‚úÖ Successful experiments: {len(successful_experiments)}/{len(experiment_results)}\")\n",
    "print(f\"‚ùå Failed experiments: {len(failed_experiments)}/{len(experiment_results)}\")\n",
    "\n",
    "if successful_experiments:\n",
    "    # Find best performing experiment\n",
    "    best_experiment = max(successful_experiments, \n",
    "                         key=lambda x: x.metrics.get('improvement_vs_baseline', -float('inf')))\n",
    "    \n",
    "    print(f\"\\nüèÜ Best performing experiment:\")\n",
    "    print(f\"   Hypothesis: {best_experiment.hypothesis_id}\")\n",
    "    print(f\"   Mean error: {best_experiment.metrics['mean_error']:.3f} pixels\")\n",
    "    print(f\"   Improvement: {best_experiment.metrics['improvement_vs_baseline']:+.1f}%\")\n",
    "    \n",
    "    # Performance comparison\n",
    "    baseline_error = RESEARCH_CONTEXT['baseline_performance']['mean_error']\n",
    "    improvements = [r.metrics.get('improvement_vs_baseline', 0) for r in successful_experiments]\n",
    "    \n",
    "    print(f\"\\nüìà Performance Overview:\")\n",
    "    print(f\"   Baseline error: {baseline_error:.2f} pixels\")\n",
    "    print(f\"   Average improvement: {np.mean(improvements):+.1f}%\")\n",
    "    print(f\"   Best improvement: {max(improvements):+.1f}%\")\n",
    "    print(f\"   Improvement range: {min(improvements):+.1f}% to {max(improvements):+.1f}%\")\n",
    "\n",
    "# Visualize results\n",
    "if len(experiment_results) > 1:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Mean errors\n",
    "    hypothesis_ids = [r.hypothesis_id for r in experiment_results if r.success]\n",
    "    mean_errors = [r.metrics['mean_error'] for r in experiment_results if r.success]\n",
    "    \n",
    "    if mean_errors:\n",
    "        colors = ['green' if err < baseline_error else 'orange' for err in mean_errors]\n",
    "        bars1 = ax1.bar(hypothesis_ids, mean_errors, color=colors, alpha=0.7)\n",
    "        ax1.axhline(y=baseline_error, color='red', linestyle='--', alpha=0.8, label='Baseline')\n",
    "        ax1.set_ylabel('Mean Error (pixels)')\n",
    "        ax1.set_title('Mean Error by Hypothesis')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, error in zip(bars1, mean_errors):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{error:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Plot 2: Improvement percentages\n",
    "    improvements = [r.metrics.get('improvement_vs_baseline', 0) for r in experiment_results if r.success]\n",
    "    \n",
    "    if improvements:\n",
    "        colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
    "        bars2 = ax2.bar(hypothesis_ids, improvements, color=colors, alpha=0.7)\n",
    "        ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "        ax2.set_ylabel('Improvement (%)')\n",
    "        ax2.set_title('Improvement vs Baseline')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, imp in zip(bars2, improvements):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height + (0.2 if height >= 0 else -0.4),\n",
    "                    f'{imp:+.1f}%', ha='center', va='bottom' if height >= 0 else 'top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nüìã Analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI-Assisted Results Interpretation\n",
    "\n",
    "Get AI assistance to interpret results and suggest next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ AI Consultation Cell #4: Results Interpretation\n",
    "\n",
    "**Use this cell to get AI insights on your experimental results:**\n",
    "\n",
    "---\n",
    "\n",
    "**System:** You are an expert data scientist and computer vision researcher. Analyze experimental results and provide actionable insights for algorithm improvement.\n",
    "\n",
    "**User:** I conducted systematic experiments on template matching optimization. Here are the results:\n",
    "\n",
    "**Baseline Performance:** 5.63¬±0.17 pixels mean error\n",
    "\n",
    "**Experimental Results:**\n",
    "[COPY THE EXPERIMENT SUMMARY TABLE FROM ABOVE]\n",
    "\n",
    "**Hypotheses Tested:**\n",
    "1. H1: Adaptive patch sizes (15, 21, 31) per landmark\n",
    "2. H2: Increased PCA components (20 ‚Üí 35)\n",
    "3. H3: Relaxed geometric constraints (Œª = 0.1 ‚Üí 0.05)\n",
    "\n",
    "**Questions:**\n",
    "1. What do these results tell us about the algorithm's behavior?\n",
    "2. Which findings are most significant and why?\n",
    "3. What should be the next set of experiments?\n",
    "4. Are there any unexpected results that warrant deeper investigation?\n",
    "5. How would you prioritize further research directions?\n",
    "\n",
    "**Assistant:** [PASTE AI RESPONSE HERE]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Accumulation and Next Steps\n",
    "\n",
    "Document insights and plan future research directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö KNOWLEDGE ACCUMULATION\n",
    "\n",
    "# Document key insights from experiments\n",
    "EXPERIMENT_INSIGHTS = {\n",
    "    \"session_date\": datetime.now().isoformat(),\n",
    "    \"research_context\": RESEARCH_CONTEXT,\n",
    "    \"hypotheses_tested\": len(HYPOTHESES),\n",
    "    \"successful_experiments\": len([r for r in experiment_results if r.success]),\n",
    "    \"key_findings\": [\n",
    "        # Edit these based on your results and AI consultation\n",
    "        \"Hypothesis H1 (adaptive patches) showed [describe result]\",\n",
    "        \"Hypothesis H2 (more PCA components) demonstrated [describe result]\", \n",
    "        \"Hypothesis H3 (relaxed constraints) revealed [describe result]\",\n",
    "        \"Overall improvement potential: [summarize best improvements]\"\n",
    "    ],\n",
    "    \"unexpected_results\": [\n",
    "        # Document any surprising findings\n",
    "        \"[Describe any unexpected experimental outcomes]\"\n",
    "    ],\n",
    "    \"ai_insights\": [\n",
    "        # Copy key insights from AI consultations\n",
    "        \"[Copy relevant AI insights from consultation cells above]\"\n",
    "    ],\n",
    "    \"technical_learnings\": [\n",
    "        \"Parameter sensitivity patterns observed\",\n",
    "        \"Algorithm behavior insights\",\n",
    "        \"Implementation considerations\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Generate next research priorities\n",
    "NEXT_RESEARCH_PRIORITIES = {\n",
    "    \"immediate_follow_ups\": [\n",
    "        # Based on AI consultation and results\n",
    "        \"Deep dive into [most promising approach]\",\n",
    "        \"Parameter optimization for [specific finding]\",\n",
    "        \"Validation on real dataset\"\n",
    "    ],\n",
    "    \"medium_term_investigations\": [\n",
    "        \"Hybrid approach combining [successful elements]\",\n",
    "        \"Novel technique exploration: [specific AI suggestion]\",\n",
    "        \"Cross-validation of findings\"\n",
    "    ],\n",
    "    \"long_term_research\": [\n",
    "        \"Integration with clinical workflow\",\n",
    "        \"Robustness across different pathologies\",\n",
    "        \"Real-time performance optimization\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save experiment session\n",
    "def save_experiment_session(insights: Dict, priorities: Dict, results: List[ExperimentResult]):\n",
    "    \"\"\"Save complete experiment session for future reference.\"\"\"\n",
    "    session_data = {\n",
    "        \"metadata\": {\n",
    "            \"session_id\": f\"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "            \"researcher\": \"[Your name/ID]\",\n",
    "            \"session_duration\": \"[Estimate session time]\"\n",
    "        },\n",
    "        \"insights\": insights,\n",
    "        \"priorities\": priorities,\n",
    "        \"detailed_results\": [asdict(r) for r in results]\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    output_dir = PROJECT_ROOT / \"results\" / \"prompt_experiments\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    session_file = output_dir / f\"experiment_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(session_file, 'w') as f:\n",
    "        json.dump(session_data, f, indent=2)\n",
    "    \n",
    "    return session_file\n",
    "\n",
    "# Display summary\n",
    "print(\"üìö Research Session Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üéØ Research Objective: {RESEARCH_CONTEXT['objective']}\")\n",
    "print(f\"üß™ Hypotheses Tested: {len(HYPOTHESES)}\")\n",
    "print(f\"‚úÖ Successful Experiments: {len([r for r in experiment_results if r.success])}\")\n",
    "\n",
    "print(f\"\\nüîë Key Findings:\")\n",
    "for i, finding in enumerate(EXPERIMENT_INSIGHTS['key_findings'], 1):\n",
    "    print(f\"   {i}. {finding}\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Research Priorities:\")\n",
    "print(f\"   Immediate: {len(NEXT_RESEARCH_PRIORITIES['immediate_follow_ups'])} items\")\n",
    "print(f\"   Medium-term: {len(NEXT_RESEARCH_PRIORITIES['medium_term_investigations'])} items\")\n",
    "print(f\"   Long-term: {len(NEXT_RESEARCH_PRIORITIES['long_term_research'])} items\")\n",
    "\n",
    "# Optional: Save session\n",
    "save_session = input(\"\\nüíæ Save this experiment session? (y/n): \").lower().startswith('y')\n",
    "if save_session:\n",
    "    session_file = save_experiment_session(EXPERIMENT_INSIGHTS, NEXT_RESEARCH_PRIORITIES, experiment_results)\n",
    "    print(f\"üìÅ Session saved to: {session_file}\")\n",
    "else:\n",
    "    print(\"üìã Session not saved (results still available in notebook)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Workflow Template\n",
    "\n",
    "Use this template for future prompt-driven research sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Iterative Research Workflow\n",
    "\n",
    "**Follow this workflow for systematic AI-assisted research:**\n",
    "\n",
    "#### Phase 1: Problem Definition (15 minutes)\n",
    "1. ‚úÖ **Define research context** - Update RESEARCH_CONTEXT\n",
    "2. ‚úÖ **Identify constraints** - Computational, data, interpretability\n",
    "3. ‚úÖ **Set success criteria** - Quantitative and qualitative metrics\n",
    "\n",
    "#### Phase 2: AI Consultation (20 minutes)\n",
    "1. ‚úÖ **Algorithm analysis** - Get AI insights on current approach\n",
    "2. ‚úÖ **Parameter optimization** - Systematic tuning guidance\n",
    "3. ‚úÖ **Novel approaches** - Explore innovative techniques\n",
    "\n",
    "#### Phase 3: Hypothesis Generation (15 minutes)\n",
    "1. ‚úÖ **Generate structured hypotheses** - Based on AI consultation\n",
    "2. ‚úÖ **Risk assessment** - Evaluate feasibility and expected impact\n",
    "3. ‚úÖ **Prioritization** - Order by potential impact vs. effort\n",
    "\n",
    "#### Phase 4: Experiment Execution (30-60 minutes)\n",
    "1. ‚úÖ **Automated testing** - Run systematic experiments\n",
    "2. ‚úÖ **Results collection** - Gather quantitative metrics\n",
    "3. ‚úÖ **Quality control** - Verify experiment validity\n",
    "\n",
    "#### Phase 5: Analysis and Insights (20 minutes)\n",
    "1. ‚úÖ **Statistical analysis** - Compare with baseline\n",
    "2. ‚úÖ **AI interpretation** - Get expert insights on results\n",
    "3. ‚úÖ **Knowledge documentation** - Record findings and learnings\n",
    "\n",
    "#### Phase 6: Next Steps Planning (10 minutes)\n",
    "1. ‚úÖ **Immediate follow-ups** - Quick wins and validations\n",
    "2. ‚úÖ **Medium-term research** - Deeper investigations\n",
    "3. ‚úÖ **Long-term strategy** - Research roadmap\n",
    "\n",
    "### üí° Pro Tips for Effective AI-Assisted Research\n",
    "\n",
    "1. **Be specific in AI prompts** - Include exact parameters, dataset details, and constraints\n",
    "2. **Validate AI suggestions** - Always test recommendations empirically\n",
    "3. **Document everything** - Keep detailed records of insights and results\n",
    "4. **Iterate quickly** - Test multiple small hypotheses rather than few large ones\n",
    "5. **Cross-validate findings** - Verify results on different datasets/conditions\n",
    "6. **Build on previous sessions** - Reference past experiments and insights\n",
    "\n",
    "### üéØ Success Metrics for Research Sessions\n",
    "\n",
    "- **Quantitative**: Measurable performance improvements\n",
    "- **Qualitative**: New insights about algorithm behavior\n",
    "- **Methodological**: Improved experimental processes\n",
    "- **Strategic**: Clear next steps and research direction\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ Happy researching! Use this framework to systematically improve your template matching algorithms with AI assistance.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}